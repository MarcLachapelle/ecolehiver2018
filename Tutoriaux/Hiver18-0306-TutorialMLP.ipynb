{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"AFT-Hiver18TutorialMLP.ipynb","version":"0.3.2","views":{},"default_view":{},"provenance":[],"collapsed_sections":["0hcZaIKtavmH","P0ksgXqwavmK","LLXjNiDTavmK","K6gjERhgavmL","nsQtU9ylavmL","fMUyZNxdavmW","ve8sOocWavma","86OZRLrjavmd","V11J3Jihavmy"],"toc_visible":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"cells":[{"metadata":{"id":"mipSoOVlavkb","colab_type":"text"},"cell_type":"markdown","source":["<h1 align=\"center\">École d'Hiver 2018</h1> \n","<br/>\n","<h1 align=\"center\">Tutoriel : Données Catégorielles (MLP)</h1> \n"]},{"metadata":{"id":"vGTFwlPL1uBt","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# http://pytorch.org/\n","from os import path\n","from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n","platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n","\n","accelerator = 'cu80' if path.exists('/opt/bin/nvidia-smi') else 'cpu'\n","\n","!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.3.0.post4-{platform}-linux_x86_64.whl torchvision\n","import torch"],"execution_count":0,"outputs":[]},{"metadata":{"id":"HORYKkABrbV6","colab_type":"text"},"cell_type":"markdown","source":["  "]},{"metadata":{"id":"nqvhR0ebavmE","colab_type":"text"},"cell_type":"markdown","source":["Pour mener à bien un projet en deep learning, on a besoin de:\n","<ul>\n","<li>Une <b> tâche à résoudre</b> ainsi que des <b>données</b> pour la supporter </li>\n","<li>Un <b>modèle</b> (réseau de neurones) à entraîner </li>\n","<li>Une <b>fonction de coût</b> à optimiser </li>\n","<li>Un <b>optimiseur</b> qui ajustera les paramètres (poids) du réseau de neurones</li>\n","</ul>"]},{"metadata":{"id":"Y8_pfpu2f6AO","colab_type":"text"},"cell_type":"markdown","source":["## 1) Tâche - Prédiction de la survie suite à un naufrage"]},{"metadata":{"id":"B5piZxYUhSzq","colab_type":"text"},"cell_type":"markdown","source":["Notre objectif est de <b>prédire si un passager a survécu ou non à la suite du naufrage du Titanic</b>."]},{"metadata":{"id":"y4GuYNDFavlU","colab_type":"text"},"cell_type":"markdown","source":["### a) Le dataset Titanic"]},{"metadata":{"id":"NiOJx2ytavlU","colab_type":"text"},"cell_type":"markdown","source":["Le dataset Titanic peut être téléchargé à l'adresse suivante:  https://github.com/afansi/winterschool18/blob/master/titanic3.csv?raw=true.<br/>\n","Nous utiliserons le paquet <a href=\"https://pandas.pydata.org/\"> <b> Pandas </b></a>   pour le charger en mémoire de notre ordinateur."]},{"metadata":{"id":"bX_RSiffavlW","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["import numpy as np\n","import pandas as pd"],"execution_count":0,"outputs":[]},{"metadata":{"id":"cTBxMNU0avlb","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["titanic_df = pd.read_csv(\n","    'https://github.com/afansi/winterschool18/blob/master/titanic3.csv?raw=true',\n","    sep='\\t', \n","    index_col=None, \n","    na_values=['NA']\n",")"],"execution_count":0,"outputs":[]},{"metadata":{"id":"P3dd9D6favld","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["titanic_df.head()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"yj88WmCmavlf","colab_type":"text"},"cell_type":"markdown","source":["### La signification des différentes colonnes (features) est la suivante:\n","\n","<ol>\n","\n","  <li> <b>pclass</b>: Classe du Passager (1 = première; 2 = seconde; 3 = troisième) </li>\n","  <li> <b>survived</b>: Survie (0 = non; 1 = oui) </li>\n","  <li> <b>name</b>: Nom </li>\n","  <li> <b>sex</b>: Sexe </li>\n","  <li> <b>age</b>: Âge </li>\n","  <li> <b>sibsp</b>: Nombre de frères, sœurs, ou conjoints à bord </li>\n","  <li> <b>parch</b>: Nombre de parents ou enfants à bord </li>\n","  <li> <b>ticket</b>: Numéro de ticket </li>\n","  <li> <b>fare</b>: Tarif passager </li>\n","  <li> <b>cabin</b>: Numéro de cabine </li>\n","  <li> <b>embarked</b>: Port d'embarquement (C = Cherbourg; Q = Queenstown; S = Southampton) </li>\n","  <li> <b>boat</b>: Canot de sauvetage (si le passager a survécu) </li>\n","  <li> <b>body</b>: Numéro de corps (si le passager n'a pas survécu et que son corps a été retrouvé) </li>\n","  <li> <b>home.dest</b>: la destination du passager </li>\n"," </ol>\n"]},{"metadata":{"id":"peuLBXx1rbWL","colab_type":"text"},"cell_type":"markdown","source":["### b) Comprendre son jeu de données : Prétraitement du dataset"]},{"metadata":{"id":"XwrcS_LSyJE7","colab_type":"text"},"cell_type":"markdown","source":["### Questions: \n","\n","<b> a) Y'a t'il des features sans aucune utilité pour la tâche à accomplir? Si oui, lesquelles et pourquoi ? <br/>\n","<br/>\n","<b> b) Un réseau de neurones ne sait manipuler que des données numériques. Cependant, certaines features importantes pour la tâche définie sont non-numériques. Lesquelles? Devez-vous exclure ces features du jeu de données? Si oui, pourquoi? Si non, comment les passeriez-vous à un réseau de neurones?</b><br/>"]},{"metadata":{"id":"__vcZhPnavlg","colab_type":"text"},"cell_type":"markdown","source":["\n"," \n"," Le dataset pré-processé peut être téléchargé à l'adresse suivante:  https://github.com/afansi/winterschool18/blob/master/titanic_prepocess.xls?raw=true."]},{"metadata":{"id":"JJ0--SDpavlg","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["titanic_preprocess_df = pd.read_csv(\n","    'https://github.com/afansi/winterschool18/blob/master/titanic_prepocess.csv?raw=true', \n","    sep=',', \n","    index_col=None\n",")"],"execution_count":0,"outputs":[]},{"metadata":{"id":"YqySSMZFavli","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["titanic_preprocess_df.head()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"tEd92PBpavlm","colab_type":"text"},"cell_type":"markdown","source":[" "]},{"metadata":{"id":"QJcs6PUTavlm","colab_type":"text"},"cell_type":"markdown","source":["### c) Découpage en Train / Validation / Test"]},{"metadata":{"id":"Bjbgvffmavlo","colab_type":"text"},"cell_type":"markdown","source":["En général, le dataset est divisé en trois parties:\n","\n","<ol>\n","<li> <b> Train</b> (en général, 60 % du dataset): utilisée pour entraîner le modèle de classification.</li>   \n","<li> <b> Validation</b> (en général, 20 % du dataset): utilisée pour évaluer les performances du modèle en cours d'entraînement.</li>   \n","<li> <b> Test</b> (en général, 20 % du dataset): utilisée pour évaluer les performances de généralisation du modèle entraîné. </li>\n","</ol>"]},{"metadata":{"id":"GBmL8VBOavlo","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["np.random.seed(1234)\n","train, validate, test = np.split(\n","    titanic_preprocess_df.sample(frac=1, random_state=134), \n","    [int(.6*len(titanic_preprocess_df)), \n","     int(.8*len(titanic_preprocess_df))\n","    ]\n",")\n","\n","X_train = train.drop(['survived'], axis=1).values\n","y_train = train['survived'].values\n","\n","X_val = validate.drop(['survived'], axis=1).values\n","y_val = validate['survived'].values\n","\n","X_test = test.drop(['survived'], axis=1).values\n","y_test = test['survived'].values"],"execution_count":0,"outputs":[]},{"metadata":{"id":"IOJNGRugrbWX","colab_type":"text"},"cell_type":"markdown","source":["   "]},{"metadata":{"id":"PG7-PF6brbWY","colab_type":"text"},"cell_type":"markdown","source":["   "]},{"metadata":{"id":"obEPHnlTavkc","colab_type":"text"},"cell_type":"markdown","source":["## 2) Modèle: Multi-Layer Perceptrons (MLP)"]},{"metadata":{"id":"qhN5GL6Gavks","colab_type":"text"},"cell_type":"markdown","source":["Pour résoudre notre tâche, nous allons utiliser un MLP avec les caractéristiques suivantes:\n"," <ul>\n"," <li> <b> 4 </b> couches (<b> 3 </b> couches cachées et <b> 1 </b> couche de sortie) </li>\n"," <li> la dimension des données d'entrées est de <b> 12 . </b></li>\n"," <li> les dimensions des différentes couches sont <b> 20, 40, 20, 2. </b> </li>\n"," <li> utilisation de la fonction d'activation <b> RELU </b> pour les 3 couches cachées.</li>\n"," </ul>"]},{"metadata":{"id":"qTlg5x9tavkd","colab_type":"text"},"cell_type":"markdown","source":["### a) Illustration"]},{"metadata":{"id":"XbvYDBnVrbWc","colab_type":"text"},"cell_type":"markdown","source":["<img src=\"https://github.com/afansi/winterschool18/blob/master/figures_tuto.pptx.png?raw=true\", width=900,  height=500>"]},{"metadata":{"id":"701t0e-ravkr","colab_type":"text"},"cell_type":"markdown","source":["### b) Implémentation du modèle en PyTorch"]},{"metadata":{"id":"ZKzgFV9Favkt","colab_type":"text"},"cell_type":"markdown","source":["#### 1 - PyTorch en bref"]},{"metadata":{"id":"Vrus_-F0avkt","colab_type":"text"},"cell_type":"markdown","source":["PyTorch est un paquet Python qui fournit deux fonctionnalités de haut niveau:\n","<ul>\n","<li> Opérations sur des tenseurs (comme NumPy) avec support GPU </li>\n","<li> Réseaux de neurones profonds construits sur un système de <b><a href=\"http://pytorch.org/docs/master/notes/autograd.html\"> différentiation automatique</a></b> appelé  <b> <a href=\"http://pytorch.org/docs/master/autograd.html#\">Autograd </a></b>.</li>\n","</ul>\n","<br/>\n","Voici <a href=\"http://pytorch.org/docs/master/torch.html\"> La documentation principale sur PyTorch </a> et celle relative <a href=\"http://pytorch.org/docs/master/nn.html\"> aux réseaux de neurones </a>.\n"]},{"metadata":{"id":"mgtCculMavku","colab_type":"text"},"cell_type":"markdown","source":["#### 2 - Détails techniques"]},{"metadata":{"id":"m4F5cyijavkv","colab_type":"text"},"cell_type":"markdown","source":["<ul>\n","<li> La classe <b><a href=\"http://pytorch.org/docs/master/nn.html#module\">torch.nn.Module</a></b>: \n","\n","    <br/> En PyTorch, tout réseau de neurones doit <b>hériter</b> de cette classe ou de ses descendantes (sous-classes).\n","    <br/> \n","</li>   \n","<li> La méthode <b>forward</b>: \n","    <br/> Toute classe définissant un réseau de neurones doit <b>implémenter</b> la méthode  <b>forward</b>. C'est cette méthode qui définit les opérations effectuées par le réseau de neurones et, le cas échéant, construit le graphe computationnel correspondant.\n","    <br/> \n","</li>  \n","<li> la classe <b><a href=\"http://pytorch.org/docs/master/nn.html#torch.nn.Linear\">`torch.nn.Linear(in_features, out_features)`</a></b>: \n","    <br/> Cette classe implémente <b>une couche de réseau dense</b> sans fonction d'activation à sa sortie. <br/> Elle prend par défaut deux paramètres: \n","    <ul>\n","    <li><b>in_features</b>: la dimension des données en entrée de la couche. </li>\n","    <li><b>out_features</b>: la dimension des données en sortie de la couche. </li>    \n","    </ul>\n","    \n","</li>\n","<li> le module <b><a href=\"http://pytorch.org/docs/master/nn.html#torch-nn-functional\">torch.nn.functional</a></b>: \n","<br/> Il définit un ensemble de fonctions qui peuvent être appliquées aux sorties des différentes composantes d'un réseau de neurones. On y retrouve par example:\n","    <ul>\n","    <li> des fonctions non-lineaires: <b><a href=\"http://pytorch.org/docs/master/nn.html#id36\">sigmoid</a></b>, <b><a href=\"http://pytorch.org/docs/master/nn.html#id35\">tanh</a></b>, <b><a href=\"http://pytorch.org/docs/master/nn.html#id22\">relu</a></b>, <a href=\"http://pytorch.org/docs/master/nn.html#non-linear-activation-functions\">etc...</a> </li> \n","    <li> des fonctions de coûts: <b><a href=\"http://pytorch.org/docs/master/nn.html#mse-loss\">mse_loss</a></b>, <b><a href=\"http://pytorch.org/docs/master/nn.html#nll-loss\">nll</a></b>, <b><a href=\"http://pytorch.org/docs/master/nn.html#cross-entropy\">cross_entropy</a></b>, <a href=\"http://pytorch.org/docs/master/nn.html#id42\">etc ...</a> </li> \n","    <li> des fonctions de régularisation: <b><a href=\"http://pytorch.org/docs/master/nn.html#id38\">droupout</a></b>, <a href=\"http://pytorch.org/docs/master/nn.html#dropout-functions\">etc ...</a>  </li> \n","    <li> <a href=\"http://pytorch.org/docs/master/nn.html#torch-nn-functional\">et plein encore ...</a> </li> \n","    </ul>\n","    <br/> \n","</li>\n","<li> la classe <b><a href=\"http://pytorch.org/docs/master/autograd.html#variable\">torch.autograd.Variable</a></b>: \n","    <br/> Pour faire simple, cette classe permet <b>d'encapsuler</b> les données à faire ingérer par un réseau de neurones. C'est à travers elle que tout le mécanisme de <b><a href=\"http://pytorch.org/docs/master/notes/autograd.html\">diférentiation automatique</a></b> s'effectue. \n","</li>\n","</ul>"]},{"metadata":{"id":"DMn6-Jepavkw","colab_type":"text"},"cell_type":"markdown","source":["#### 3 - Implémentation"]},{"metadata":{"id":"8NyQGwC-avkw","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","torch.manual_seed(1234)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"NnARqxyusfCl","colab_type":"text"},"cell_type":"markdown","source":["#### Exercice: \n","\n","Compléter la classe NeuralNet afin de satisfaire aux contraintes du réseau de neurones telles que décrites."]},{"metadata":{"id":"xR5eBfIbavk0","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["class NeuralNet(nn.Module):\n","    def __init__(self):\n","        super(NeuralNet, self).__init__()        \n","        self.fc1 = nn.Linear(12, 20)\n","        \n","        # À Completer avec la définition d'autres couches .....\n","        \n","\n","    def forward(self, x):\n","       x = F.relu(self.fc1(x))\n","    \n","       # À Completer avec l'appel à d'autres couches .....\n","    \n","       \n","       return x"],"execution_count":0,"outputs":[]},{"metadata":{"id":"lPjULuGrrbWv","colab_type":"text"},"cell_type":"markdown","source":["   "]},{"metadata":{"id":"wv74TbIWavlr","colab_type":"text"},"cell_type":"markdown","source":["### c) Datasets en PyTorch"]},{"metadata":{"id":"9_LJtG-Xavlt","colab_type":"text"},"cell_type":"markdown","source":["PyTorch offre plusieurs utilitaires pour faciliter le traitement des données, rendant ainsi le code plus lisible. <br/> Un de ces utilitaires est la classe <b><a href=\"http://pytorch.org/docs/master/data.html#\"> Dataset (torch.utils.data.Dataset)</a> </b> et ses sous-classes qui offrent une interface facile d'utilisation pour manipuler un dataset.<br/>\n","Pour plus d'informations, veuillez vous reportez aux urls suivantes: \n","<ul>\n","<li>http://pytorch.org/docs/master/data.html</li>\n","<li>http://pytorch.org/tutorials/beginner/data_loading_tutorial.html</li>\n","</ul>\n","<br/>\n","Nous utiliserons la sous-classe <b><a href=\"http://pytorch.org/docs/master/data.html#\"> TensorDataset</a> </b> qui permet d'encapsuler ensemble les features et la target d'un jeu de données. Nous encapsulerons les données de Train, Validation, et Test définies dans la section précédente.\n"]},{"metadata":{"id":"1JtT4tV7avlt","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["import torch.utils.data\n","\n","train_dataset = torch.utils.data.TensorDataset(\n","    torch.from_numpy(X_train).float(), \n","    torch.from_numpy(y_train).long()\n",")\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"1Ir1vAYisn-x","colab_type":"text"},"cell_type":"markdown","source":["#### Exercice: \n","\n","Définissez en PyTorch les datasets pour les données de Validation et de Test."]},{"metadata":{"id":"6lR0SLpJrbW3","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# À compléter\n","\n","val_dataset = ...\n","\n","test_dataset = ..."],"execution_count":0,"outputs":[]},{"metadata":{"id":"_ORLde1MrbW6","colab_type":"text"},"cell_type":"markdown","source":["  "]},{"metadata":{"id":"OvLnHRZ5avk2","colab_type":"text"},"cell_type":"markdown","source":["### d) Exécution d'un réseau de neurones"]},{"metadata":{"id":"uEXgJMDDavk3","colab_type":"text"},"cell_type":"markdown","source":["Dans cette section, nous exécuterons notre réseau de neurones sur des données aloitoirement générées. \n","\n","<b>Important à savoir:</b>\n","    En PyTorch, il existe deux modes d'exécution d'un réseau de neurones:\n","    <ul>\n","    <li> <b>train</b>: dans ce mode, tous les mécanismes d'apprentissage (construction du graphe computationnel, auto-différentiation) sont mis en place à chaque exécution du réseau. Il est utilisé lorsque le réseau est en cours d'entraînement.</li>\n","    <li> <b>eval</b>: dans ce mode, aucun mécanisme d'apprentissage est mis en place. On dit aussi que le modèle est en mode <b>inférence</b>. Il est utilisé lorsque le réseau est en cours d'évaluation.</li>\n","    </ul>\n","<br/>    \n","Nous utiliserons le mode <b>eval</b> dans cette section."]},{"metadata":{"id":"EVx1EkgZavk3","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["from torch.autograd import Variable"],"execution_count":0,"outputs":[]},{"metadata":{"id":"gzcABMezavk6","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# Instantiation du réseau\n","neural_net = NeuralNet()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"cQHZtxEbavk8","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# activation du mode eval\n","neural_net = neural_net.eval()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"JM22oj2wavl1","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# Sélection des 5 premières données du dataset de validation\n","data, target = val_dataset[0:5]"],"execution_count":0,"outputs":[]},{"metadata":{"id":"xVaky0saavl5","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# Encapusaulation des données dans la classe Variable\n","data = Variable(data)\n","target = Variable(target)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"7NR3Ggdoavl7","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# Execution du réseau de neurones\n","output = neural_net(data)   \n","# neural_net.forward(data)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"cMRKVz_wavl9","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# Tranformation des resultat en probabilités en utilisant la fonction SOFTMAX\n","output_proba = F.softmax(output, dim=1)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"SsyrFZLxavlQ","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# Affichage des probabilités\n","print(output_proba)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"fVep0BElavlS","colab_type":"text"},"cell_type":"markdown","source":["Les lignes définissent la sortie du réseau, en terme de <b> probabilités sur deux classes</b>, <b>mort</b> (0 - 1ere colonne) ou <b>survie</b> (1 - 2nde colonne), pour chacune des 5 données en entrée."]},{"metadata":{"id":"0bG7QIaQrbXU","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# Affichage des prédictions (classe ayant la plus grande probabilités)\n","_, prediction = torch.max(output_proba, dim=1)\n","print(prediction)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"yDwvhQvnrbXY","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# Affichage de la vrai target\n","print(target)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"gGjtCBE9rbXa","colab_type":"text"},"cell_type":"markdown","source":[" "]},{"metadata":{"id":"4qY14Y94rbXb","colab_type":"text"},"cell_type":"markdown","source":["### Questions: \n","\n","<b> Que constatez vous ? </b> <br/>\n","<b> Et pourquoi? </b>"]},{"metadata":{"id":"37Sy1S6nrbXb","colab_type":"text"},"cell_type":"markdown","source":[" "]},{"metadata":{"id":"0uySA2TCavmD","colab_type":"text"},"cell_type":"markdown","source":["## 3) Fonction de coût et Optimiseur"]},{"metadata":{"id":"EkoobCLMavmE","colab_type":"text"},"cell_type":"markdown","source":["### a) Fonction de coût"]},{"metadata":{"id":"qkX7uSXQavmF","colab_type":"text"},"cell_type":"markdown","source":["La fonction de coût doit être définie en fonction de la tâche que nous souhaitons réaliser.\n","\n","PyTorch offre <a href=\"http://pytorch.org/docs/master/nn.html#id42\">une multitude de fonctions de coûts</a> prêtes à l'emploi.\n","\n","Pour des problèmes de classification, la fonction de coût usuelle est <b> l'entropie croisée (cross-entropy)</b> et c'est elle que nous allons utiliser dans ce tutoriel. En PyTorch, elle est définie par la fonction <b><a href=\"http://pytorch.org/docs/master/nn.html#cross-entropy\">`torch.nn.functional.cross_entropy`</a></b>. "]},{"metadata":{"id":"FHnfYeS5avmF","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["import torch.nn.functional as F\n","\n","\n","def cost_function(prediction, target):\n","    loss = F.cross_entropy(prediction, target)\n","    return loss"],"execution_count":0,"outputs":[]},{"metadata":{"id":"IQV8hoPnrbXg","colab_type":"text"},"cell_type":"markdown","source":["  "]},{"metadata":{"id":"P5VcnkACrbXh","colab_type":"text"},"cell_type":"markdown","source":["### b) Rétro-propagation du gradient"]},{"metadata":{"id":"0hcZaIKtavmH","colab_type":"text"},"cell_type":"markdown","source":["En Pytorch, grâce au mécanisme de differentiation automatique <a href=\"http://pytorch.org/docs/master/notes/autograd.html\">Autograd</a>, il est possible de calculer automatiquement le gradient de la fonction de coût et de le rétro-propager à travers le graphe computationnel.\n","\n","Pour ce faire, une fois la fonction de coût calculée et stockée dans une variable, il suffit d'appeler la méthode <b> backward() </b> de cette dernière.<br/>\n","\n","#### Snippet de rétro-propagation:\n","\n","loss = fonction_de_cout(...) <br/>\n","loss.backward()<br/>"]},{"metadata":{"id":"8YNo_ymYavmH","colab_type":"text"},"cell_type":"markdown","source":["### c) Optimiseur"]},{"metadata":{"id":"Y4AlX9TwavmH","colab_type":"text"},"cell_type":"markdown","source":["PyTorch fournit un <a href=\"http://pytorch.org/docs/master/optim.html#algorithms\">ensemble de méthodes d'optimisation</a> couramment utilisées dans la communauté de Deep Learning. Parmi ces méthodes, on y retrouve notamment: \n","<ul>\n","<li><b>SGD</b> (Stochastic Gradient Descent)</li>\n","<li><b>Adam</b> (Adaptive Moment Estimation): variante de la méthode de descente de gradient dans laquelle le taux d'apprentissage est ajusté pour chaque paramètre. Cet ajustement est basé sur le momentum (moyenne glissante des gradients) et la courbure (moyenne glissante de la dérivée seconde). Cet optimiseur a démontré de très bonnes performamces par rapport à SGD dans la litérature.</li>\n","<li>...</li>\n","</ul>\n"]},{"metadata":{"id":"nqkahMGirbXk","colab_type":"text"},"cell_type":"markdown","source":["\n","Pour pouvoir utiliser un optimiseur en PyTorch, il faut l'instancier en lui passant les éléments suivants:\n","<ul>\n","<li><b>les paramètres du réseau de neurones</b>: ceux-ci s'obtiennent à l'aide de la methode <b>parameters()</b> sur le modèle instanciée.</li>\n","<li><b>le learning rate (lr)</b>: c'est le taux d'apprentissage à utiliser pour la mise à jour des paramètres du réseau de neurones pendant le processus d'optimization.</li>\n","<li>D'autres paramètres propres à l'optimiseur choisi...</li>\n","</ul>\n"]},{"metadata":{"id":"jt6_Qr6ravmI","colab_type":"text"},"cell_type":"markdown","source":["PyTorch offre un interface simplifiée pour interagir avec tout optimiseur:\n","<ul>\n","<li><b>zero_grad()</b>: Permet d'effacer les gradients des paramètres du réseau de neurones à optimiser. Elle est appelée <b>au début d'une étape d'optimisation</b> afin de re-initialiser les infos sur les paramètres à optimiser. </li>\n","<li><b>step()</b>: Permet d'effectuer une étape d'optimisation. Elle est appelée <b>après une étape de rétro-propagation du gradient</b>.</li>\n","</ul>"]},{"metadata":{"id":"fZ-lKExqavmI","colab_type":"text"},"cell_type":"markdown","source":["Dans ce tutoriel, nous utiliserons <b>SGD</b> avec une <b>lr</b> de 0.001."]},{"metadata":{"id":"WDMOziJTavmI","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["import torch.optim as optim\n","\n","\n","optimizer = optim.SGD(neural_net.parameters(), lr=0.001) \n","# optimizer = optim.Adam(neural_net.parameters(), lr=0.001) "],"execution_count":0,"outputs":[]},{"metadata":{"id":"YqWQEO2HrbXp","colab_type":"text"},"cell_type":"markdown","source":["## 4) Entraînement"]},{"metadata":{"id":"YD1paaYCavmJ","colab_type":"text"},"cell_type":"markdown","source":["### a) Epoch, Itération, Mini-batch"]},{"metadata":{"id":"P0ksgXqwavmK","colab_type":"text"},"cell_type":"markdown","source":["#### Définitions: \n","<ol>\n","<li>\n","<b>Epoch</b> : une passe complète sur tout le dataset d'entraînement.\n","</li>\n","\n","<li>\n","<b>Itération</b> : une mise à jour des paramètres du modèle (réseau de neurones). De nombreuses itérations peuvent se produire avant la fin d'un epoch.\n","</li>\n","\n","<li>\n","<b>Mini-batch</b> : Ensemble de données utilisées pour effectuer une mise à jour des paramètres du modèle. Autrement dit, à chaque itération, un mini-batch est utilisé. \n","</li>\n","\n","</ol>\n","\n"]},{"metadata":{"id":"LLXjNiDTavmK","colab_type":"text"},"cell_type":"markdown","source":["#### Mini-batch en PyTorch: \n","\n","<ul>\n","<li>\n","PyTorch offre un utilitaire appelé <b><a href=\"http://pytorch.org/docs/master/data.html\"> torch.utils.data.DataLoader </a></b> permettant de charger un dataset quelconque et de le découper automatiquement en mini-batchs.\n","</li>\n","</ul>"]},{"metadata":{"id":"K6gjERhgavmL","colab_type":"text"},"cell_type":"markdown","source":["#### Bon à savoir: \n","\n","<ul>\n","<li>\n","Lors de l'entraînement, il est important que les données présentées au réseau apparaissent dans <b> un ordre différent d'un epoch à l'autre</b>.\n","</li>\n","</ul>"]},{"metadata":{"id":"nsQtU9ylavmL","colab_type":"text"},"cell_type":"markdown","source":["#### Définissons à présent les dataloaders pour nos trois datasets (Train, Validation, et Test)"]},{"metadata":{"id":"RGoQZSdqavmM","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}},"collapsed":true},"cell_type":"code","source":["train_batch_size = 32  # nombre de données dans un batch d'entraînement.\n","eval_batch_size = 32   # nombre de données dans un batch d'évaluation.\n","\n","\n","train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=train_batch_size, shuffle=True)\n","\n","val_loader   = torch.utils.data.DataLoader(val_dataset, batch_size=eval_batch_size, shuffle=False)\n","\n","test_loader  = torch.utils.data.DataLoader(test_dataset, batch_size=eval_batch_size, shuffle=False)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"RxxmoJVhrbXv","colab_type":"text"},"cell_type":"markdown","source":["  "]},{"metadata":{"id":"Ia3ai-GvavmP","colab_type":"text"},"cell_type":"markdown","source":["### b) Boucle principale"]},{"metadata":{"id":"v9wNZrTnavmQ","colab_type":"text"},"cell_type":"markdown","source":["Nous définissons ici notre procédure d'entraînement pour un epoch."]},{"metadata":{"id":"U71QLKbfsywm","colab_type":"text"},"cell_type":"markdown","source":["#### Exercice: \n","\n","Completez la procédure \"train\"."]},{"metadata":{"id":"ZyK9xCsZavmR","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["def train(epoch, model, train_loader, optimizer):\n","    \n","    # mettre le modèle en mode train\n","    ...\n","    \n","    # Accumulateurs d'informations\n","    total_loss = 0\n","    correct = 0\n","    \n","    # itérer sur les mini-batchs\n","    for batch_idx, (data, target) in enumerate(train_loader):\n","        \n","        # encapsuler les données dans la classe Variable\n","        data, target = ...\n","        \n","        # mettre à zéro les gradients des paramètres du réseau de neurones\n","        ...\n","        \n","        # exécuter le réseau de neurones sur les données du mini-batch\n","        prediction = ...\n","        \n","        # calculer la fonction de coût par rapport à la target\n","        loss = ...\n","        \n","        # faire la retro-propagation du gradient\n","        ...\n","        \n","        # effectuer un étape d'optimisation\n","        ...\n","        \n","        # effectuer la somme des coûts\n","        total_loss += loss.data[0]*len(data)\n","        \n","        # calculer le nombre de bonnes prédictions \n","        # (classe correspondante à la valeur maximale en sortie)        \n","        pred_classes = prediction.data.max(1, keepdim=True)[1]\n","        correct += pred_classes.eq(target.data.view_as(pred_classes)).sum()\n","        \n","    # calculer le coût moyen par epoch\n","    mean_loss = total_loss/len(train_loader.dataset)\n","    \n","    # calculer l'acurracy\n","    acc = correct / len(train_loader.dataset)\n","        \n","    print('Train Epoch: {}   Avg_Loss: {:.5f}   Acc: {}/{} ({:.3f}%)'.format(\n","        epoch, mean_loss, correct, len(train_loader.dataset),\n","        100. * acc))   \n","    \n","    # retourner le coût moyen obtenu\n","    return mean_loss, acc"],"execution_count":0,"outputs":[]},{"metadata":{"id":"PxG666rmavmU","colab_type":"text"},"cell_type":"markdown","source":["### c) Procédure d'évaluation"]},{"metadata":{"id":"vGexbWaHavmU","colab_type":"text"},"cell_type":"markdown","source":["Nous définissons ici notre procédure d'évaluation du modèle."]},{"metadata":{"id":"m-u6BPMKs6no","colab_type":"text"},"cell_type":"markdown","source":["#### Exercice: \n","\n","Completez la procédure \"eval\"."]},{"metadata":{"id":"8gQj9W5LavmU","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["def eval(model, eval_loader):\n","    \n","    # mettre le modèle en mode eval\n","    ...\n","    \n","    # Accumulateurs d'informations\n","    total_loss = 0\n","    correct = 0\n","    \n","    # itérer sur les mini-batchs\n","    for batch_idx, (data, target) in enumerate(eval_loader):\n","        \n","        # encapsuler les données dans la classe Variable\n","        data, target = ...\n","        \n","         # exécuter le réseau de neurones sur les données du mini-batch\n","        prediction = ...\n","        \n","        # calculer la fonction de coût par rapport à la target\n","        loss = ...\n","        \n","        # effectuer la somme des coûts\n","        total_loss += loss.data[0]*len(data)\n","        \n","        # calculer le nombre de bonnes prédictions \n","        # (classe correspondante à la valeur maximale en sortie)\n","        pred_classes = prediction.data.max(1, keepdim=True)[1]\n","        correct += pred_classes.eq(target.data.view_as(pred_classes)).sum()\n","    \n","    # calculer le coût moyen\n","    mean_loss = total_loss/len(eval_loader.dataset)\n","    \n","    # calculer l'acurracy\n","    acc = correct / len(eval_loader.dataset)\n","        \n","    print('Eval:  Avg_Loss: {:.5f}   Acc: {}/{} ({:.3f}%)'.format(\n","        mean_loss, correct, len(eval_loader.dataset),\n","        100. * acc)) \n","    \n","    # retourner le coût moyen obtenu\n","    return mean_loss, acc"],"execution_count":0,"outputs":[]},{"metadata":{"id":"fMUyZNxdavmW","colab_type":"text"},"cell_type":"markdown","source":["### d) Checkpointing"]},{"metadata":{"id":"lQLklQXAavmW","colab_type":"text"},"cell_type":"markdown","source":["Pour des phases d'entraînement qui requièrent beaucoup de temps, il est recommandé de sauvegarder les paramètres (poids) du réseau de neurones au fil de l'apprentissage. C'est ce que l'on appelle communément le <b> checkpointing</b>.\n","\n","PyTorch offre <a href=\"http://pytorch.org/docs/master/notes/serialization.html\">un mécanisme simple</a> pour effectuer cette opération. \n","\n","\n","\n"]},{"metadata":{"id":"Ld-Y2gF-avmX","colab_type":"text"},"cell_type":"markdown","source":["Nous implémentons ici deux méthodes:\n","<ul>\n","<li> la première pour <b> sauvegarder </b> un réseau de neurones </li>\n","<li> la seconde pour <b> charger </b> une sauvegarde de réseau de neurones </li>\n","</ul>"]},{"metadata":{"id":"dMmNpma2avmX","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}},"collapsed":true},"cell_type":"code","source":["def save_model(epoch, model, path='./'):\n","    \n","    # creation du nom de fichier indexé par la valeur de l'epoch\n","    filename = path + 'neural_network_{}.pt'.format(epoch)\n","    \n","    # sauvegarde des paramètres du modèle.\n","    torch.save(model.state_dict(), filename)\n","    \n","    \n","    return model\n","    "],"execution_count":0,"outputs":[]},{"metadata":{"id":"2ZptgqQRavmZ","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}},"collapsed":true},"cell_type":"code","source":["def load_model(epoch, model, path='./'):\n","    \n","    # creation du nom de fichier indexé par la valeur de l'epoch\n","    filename = path + 'neural_network_{}.pt'.format(epoch)\n","    \n","    # chargement des paramètres du modèle sauvegardé.\n","    model.load_state_dict(torch.load(filename))\n","    \n","    \n","    return model"],"execution_count":0,"outputs":[]},{"metadata":{"id":"ve8sOocWavma","colab_type":"text"},"cell_type":"markdown","source":["#### Important à savoir:  \n","\n","Il est également possible de sauvegarder <b>l'état de l'optimiseur</b> en PyTorch. Ceci est très important dans les situations où nous souhaitons reprendre l'entraînement du réseau de neurones à partir d'une sauvegarde donnée. Pour plus d'informations, veuillez consulter l'url suivante: https://discuss.pytorch.org/t/saving-and-loading-a-model-in-pytorch/2610/3"]},{"metadata":{"id":"8lcAP8-1avma","colab_type":"text"},"cell_type":"markdown","source":["### e) Entraînement"]},{"metadata":{"id":"_D1q9--itCUy","colab_type":"text"},"cell_type":"markdown","source":["#### Exercice: \n","\n","Completez les zones en pointillés (...)."]},{"metadata":{"id":"keMpyePsavmb","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# nombre d'epochs\n","numEpochs = 200\n","\n","# Frequence de sauvegarde\n","checkpoint_freq = 10\n","\n","# Repertoire pour la sauvegarde des données\n","path = './'\n","\n","# Accumulateurs des coûts moyens obtenu par epoch\n","train_losses = []\n","val_losses = []\n","\n","# Accumulateurs des performances par epoch\n","train_accuracies = []\n","val_accuracies = []\n","\n","# Itérer sur le nombre d'epochs\n","for epoch in range(1, numEpochs + 1):\n","    \n","    # entraîner le modèle avec le dataset de train\n","    train_loss, train_acc = ...\n","    \n","    # évaluer le modèle avec le dataset de validation\n","    val_loss, val_acc = ... \n","    \n","    # Sauvegarde des coûts obtenus\n","    train_losses.append(train_loss)    \n","    val_losses.append(val_loss)\n","    \n","    # Sauvegarde des performamces\n","    train_accuracies.append(train_acc)    \n","    val_accuracies.append(val_acc)\n","    \n","    # Checkpoint\n","    if epoch % checkpoint_freq ==0:\n","        ...\n","\n","# Sauvegarde du modèle à la fin de l'entraînement.\n","...\n","    \n","print(\"\\n\\n\\nOptimization ended.\\n\")    \n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"qPpVsyG3rbYI","colab_type":"text"},"cell_type":"markdown","source":["   "]},{"metadata":{"id":"86OZRLrjavmd","colab_type":"text"},"cell_type":"markdown","source":["### f) Execution du réseau de neurones avec des données réelles"]},{"metadata":{"id":"mklvQruYavme","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}},"collapsed":true},"cell_type":"code","source":["# activation du mode eval\n","neural_net = neural_net.eval()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"s7dAO7oRavmh","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}},"collapsed":true},"cell_type":"code","source":["# Sélection des 5 premières données du dataset de validation\n","data, target = val_dataset[0:5]"],"execution_count":0,"outputs":[]},{"metadata":{"id":"TxHhci3eavmk","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}},"collapsed":true},"cell_type":"code","source":["# Encapusaulation des données dans la classe Variable\n","data = Variable(data)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"exe3uk02avmo","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}},"collapsed":true},"cell_type":"code","source":["# Execution du réseau de neurones\n","output = neural_net(data)   # neural_net.forward(data)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"K-2QB-86avmq","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}},"collapsed":true},"cell_type":"code","source":["# Tranformation des resultat en probabilités en utilisant la fonction SOFTMAX\n","output_proba = F.softmax(output, dim=1)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"JQQDhQXvavms","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# Affichage des probabilités\n","print(output_proba)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"ygTlsP0hrbYb","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# Affichage des prédictions (classe ayant la plus grande probabilités)\n","_, prediction = torch.max(output_proba, dim=1)\n","print(prediction)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"wTzKHMuorbYd","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# Affichage de la vrai target\n","print(target)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"_5suG-0HrbYf","colab_type":"text"},"cell_type":"markdown","source":["### Questions: \n","\n","<b> Que constatez vous ? </b> <br/>"]},{"metadata":{"id":"6rKx_K6DrbYg","colab_type":"text"},"cell_type":"markdown","source":["   "]},{"metadata":{"id":"lYh_jBMurbYk","colab_type":"text"},"cell_type":"markdown","source":["  "]},{"metadata":{"id":"V11J3Jihavmy","colab_type":"text"},"cell_type":"markdown","source":["### g) Visualiser la courbe d'apprentissage"]},{"metadata":{"id":"j9_9C_tXavmz","colab_type":"text"},"cell_type":"markdown","source":["La <b>visualisation de la courbe d'apprentissage</b> permet de détecter d'éventuels problèmes survenus lors de l'apprentissage, par exemple, l'overfitting (sur-apprentissage)."]},{"metadata":{"id":"iNcbpl0tavm0","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","x = list(range(len(train_losses)))\n","\n","ax = plt.subplot(111)\n","plt.plot(x, train_losses, 'r', label=\"Train\")\n","plt.plot(x, val_losses, 'g', label=\"Validation\")\n","plt.title('Loss')\n","leg = plt.legend(loc='best', ncol=2, mode=\"expand\", shadow=True, fancybox=True)\n","leg.get_frame().set_alpha(0.99)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"g-VGQ2pMavm4","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["x = list(range(len(train_accuracies)))\n","\n","ax = plt.subplot(111)\n","plt.plot(x, train_accuracies, 'r', label=\"Train\")\n","plt.plot(x, val_accuracies, 'g', label=\"Validation\")\n","plt.title('Accuracy')\n","leg = plt.legend(loc='best', ncol=2, mode=\"expand\", shadow=False, fancybox=False)\n","leg.get_frame().set_alpha(0.99)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"nI0R1srzrbYx","colab_type":"text"},"cell_type":"markdown","source":["### Questions: \n","\n","<b> a) Que pouvez-vous dire de ces courbes ?  <br/>\n","Illustrent-ils un régime de sur-apprentissage? Si non, pourquoi? Si oui, que pouvez-vous faire pour y remédier?</b> <br/>\n","<b> b) Que pouvez-vous faire pour améliorer la performance du réseau de neurones sur des données de validation? </b><br/>"]},{"metadata":{"id":"XK_eUsq3avm8","colab_type":"text"},"cell_type":"markdown","source":["## 5) Évaluer la performance du réseau appris sur des données de Test"]},{"metadata":{"id":"4UREO5elavm8","colab_type":"text"},"cell_type":"markdown","source":["Nous pouvons finalement évaluer notre modèle apppris sur notre dataset de Test."]},{"metadata":{"id":"pPWvDM-qavm8","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["test_loss, test_acc = eval(neural_net, test_loader)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"OWy9_X_2rbY4","colab_type":"text"},"cell_type":"markdown","source":["### Questions: \n","\n","<b> a) Comparer les résultats de validation et de test ?  Le réseau appris généralise t'il aussi bien qu'espéré ? <br/>\n","b) Pensez-vous qu'il est possible d'utiliser un MLP pour d'autres types de données comme des images par exemple? </b> <br/>"]},{"metadata":{"id":"-FGMHDO1avm-","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"KIjdnH4Bavm_","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}